# 从RaftServerProxy入手

## RaftServerProxy

### 1. 构造器

没有什么特殊的地方

```java
public class RaftServerProxy implements RaftServer {
    RaftServerProxy(RaftPeerId id, StateMachine.Registry stateMachineRegistry,
      RaftProperties properties, Parameters parameters) {
    this.properties = properties;
    this.stateMachineRegistry = stateMachineRegistry;

    final RpcType rpcType = RaftConfigKeys.Rpc.type(properties, LOG::info);
    this.factory = ServerFactory.cast(rpcType.newFactory(parameters));

    this.serverRpc = factory.newRaftServerRpc(this);

    this.id = id != null? id: RaftPeerId.valueOf(getIdStringFrom(serverRpc));
    this.lifeCycle = new LifeCycle(this.id + "-" + JavaUtils.getClassSimpleName(getClass()));

    this.dataStreamServerRpc = new DataStreamServerImpl(this, parameters).getServerRpc();

    this.executor = ConcurrentUtils.newThreadPoolWithMax(
        RaftServerConfigKeys.ThreadPool.proxyCached(properties),
        RaftServerConfigKeys.ThreadPool.proxySize(properties),
        id + "-impl");

    final TimeDuration rpcSlownessTimeout = RaftServerConfigKeys.Rpc.slownessTimeout(properties);
    final TimeDuration leaderStepDownWaitTime = RaftServerConfigKeys.LeaderElection.leaderStepDownWaitTime(properties);
    this.pauseMonitor = new JvmPauseMonitor(id,
        extraSleep -> handleJvmPause(extraSleep, rpcSlownessTimeout, leaderStepDownWaitTime));
  }
}
```



### 2. start() method

```java
public class RaftServerProxy implements RaftServer {
    private final RaftPeerId id;
    private final RaftProperties properties;
    private final StateMachine.Registry stateMachineRegistry;
    
    private final RaftServerRpc serverRpc;
    private final ServerFactory factory;
    
    private volatile CompletableFuture<RaftServerImpl> impl;
    private final AtomicReference<ReinitializeRequest> reinitializeRequest = new AtomicReference<>();
    
    //构造器中调用
    private RaftServerImpl initImpl(Raftgroup group) throws IOException {
        return new RaftServerImpl(group, stateMachineRegistry.apply(group.getGroupId()), this);
    }
    
    @Override
    public void start() {
        //类名::实例方法，实参第一个参数为方法的调用者，实际上是impl.start()
        JavaUtils.getAndConsume(impl, RaftServerImpl::start);
        /**
        在GrpcService中通过
        addService()添加了
        	1. RaftServerProtocolService
        	2. RaftClientProtocolService
        	3. AdminProtocolService
        	启动RPC服务
        **/
        getServerRpc().start(); //调用RaftGRpcService.startImpl();
    }
}
```

根据Grpc.proto

```protobuf
service RaftClientProtocolService {
  // A client-to-server stream RPC to ordered async requests
  rpc ordered(stream ratis.common.RaftClientRequestProto)
      returns (stream ratis.common.RaftClientReplyProto) {}

  // A client-to-server stream RPC for unordered async requests
  rpc unordered(stream ratis.common.RaftClientRequestProto)
      returns (stream ratis.common.RaftClientReplyProto) {}
}

service RaftServerProtocolService {
  rpc requestVote(ratis.common.RequestVoteRequestProto)
      returns(ratis.common.RequestVoteReplyProto) {}

  rpc startLeaderElection(ratis.common.StartLeaderElectionRequestProto)
      returns(ratis.common.StartLeaderElectionReplyProto) {}

  rpc appendEntries(stream ratis.common.AppendEntriesRequestProto)
      returns(stream ratis.common.AppendEntriesReplyProto) {}

  rpc installSnapshot(stream ratis.common.InstallSnapshotRequestProto)
      returns(stream ratis.common.InstallSnapshotReplyProto) {}

  rpc readIndex(ratis.common.ReadIndexRequestProto)
      returns(ratis.common.ReadIndexReplyProto) {}
}

service AdminProtocolService {
  // A client-to-server RPC to set new raft configuration
  rpc setConfiguration(ratis.common.SetConfigurationRequestProto)
      returns(ratis.common.RaftClientReplyProto) {}

  rpc transferLeadership(ratis.common.TransferLeadershipRequestProto)
      returns(ratis.common.RaftClientReplyProto) {}

  // A client-to-server RPC to add a new group
  rpc groupManagement(ratis.common.GroupManagementRequestProto)
      returns(ratis.common.RaftClientReplyProto) {}

  rpc snapshotManagement(ratis.common.SnapshotManagementRequestProto)
      returns(ratis.common.RaftClientReplyProto) {}

  rpc leaderElectionManagement(ratis.common.LeaderElectionManagementRequestProto)
      returns(ratis.common.RaftClientReplyProto) {}

  rpc groupList(ratis.common.GroupListRequestProto)
      returns(ratis.common.GroupListReplyProto) {}

  rpc groupInfo(ratis.common.GroupInfoRequestProto)
      returns(ratis.common.GroupInfoReplyProto) {}
}
```

整体的rpc分为三部分，其中

* RaftClientProtocolService用于客户端和leader之间，leader处理来自客户端的读写请求
* RaftServerProtocolService用于leader/candidate和follower之间，follower用来接收来自leader/candidate的请求
* AdminProtocolService用于客户端和leader之间，leader处理来自管理员对集群的各种设置，像setConf, transferleadership, snapshot等方面都属此类

这三部分都是在GrpcService的构造函数中被添加到servers列表中，在GrpcService.Impl()中通过遍历servers列表，循环调用其start()方法

在GrpcService.startImpl() method

```java
  @Override
  public void startImpl() {
    for (Server server : servers.values()) {
      try {
        server.start();
      } catch (IOException e) {
        ExitUtils.terminate(1, "Failed to start Grpc server", e, LOG);
      }
      LOG.info("{}: {} started, listening on {}",
          getId(), JavaUtils.getClassSimpleName(getClass()), server.getPort());
    }
  }
  //在GrpcService的构造器中
  private GrpcService(RaftServer raftServer, Supplier<RaftPeerId> idSupplier,
      String adminHost, int adminPort, GrpcTlsConfig adminTlsConfig,
      String clientHost, int clientPort, GrpcTlsConfig clientTlsConfig,
      String serverHost, int serverPort, GrpcTlsConfig serverTlsConfig,
      SizeInBytes grpcMessageSizeMax, SizeInBytes appenderBufferSize,
      SizeInBytes flowControlWindow,TimeDuration requestTimeoutDuration,
      boolean useSeparateHBChannel) {
      //...
      final Server server = serverBuilder.build();
      servers.put(GrpcServerProtocolService.class.getSimpleName(), server);
      final Server adminServer = builder.build();
      servers.put(GrpcAdminProtocolService.class.getName(), adminServer);
      final Server clientServer = builder.build();
      servers.put(GrpcClientProtocolService.class.getName(), clientServer);
  }
```





根据Grpc.proto

```protobuf
service RaftClientProtocolService {
  // A client-to-server stream RPC to ordered async requests
  rpc ordered(stream ratis.common.RaftClientRequestProto)
      returns (stream ratis.common.RaftClientReplyProto) {}

  // A client-to-server stream RPC for unordered async requests
  rpc unordered(stream ratis.common.RaftClientRequestProto)
      returns (stream ratis.common.RaftClientReplyProto) {}
}
```

找到RatClientProtocolServiceImplBase的实现类，即GrpcClientProtocolService类，其ordered()方法返回的StreamObserver<RaftClientRequestProto>用来处理来自客户端的请求，处理逻辑对应在其onNext()方法，**RequestStreamObserver.onNext() -> OrderedRequestStreamObserver.processClientRequest() --> RequestStreamObserver.processClientRequest() --> RaftServerImpl.submitClientRequestAsync()**，所有的处理逻辑都在这里

针对写请求，调用appendTranscation(request, context, cacheEntry)方法

1. ServerState.appendLog(context); // append the message to its local log
2. LeaderStateImpl.addPendingRequest(permit, request, context); //put the request into the pending queue
3. LeaderStateImpl.notifySenders();





# 华丽的分割线

从RaftServerProxy开始

```java
public class RaftServerProxy {
    @Override
    public void start() throws IOException {
        lifeCycle.startAndTransition(this::startImpl, IOException.class);
    }
    
    private void startImpl() throws IOException {
        //1. 启动各个RaftGroup的RaftServerImpl类，调用其start()方法
        ConcurrentUtils.parallelForEachAsync(getImpls(), RaftServerImpl::start, executor).join();
        getServerRpc().start();
        getDataStreamRpc().start();
        paauseMonitor.start();
    }
}
```

这里的getServerRpc方法返回RaftServerRpc类型，这里的实现类为GrpcService，其start()方法最终调用为GrpcService.startImpl()方法

```java
public final class GrpcService {
    private final Map<String, Server> servers = new HashMap<>();
    public void startImpl() {
        for(Server server : servers.values()) {
            server.start();
        }
    }
}
```

servers里面有什么

```java
servers.put(GrpcServerProtocolService.class.getSimpleName(), server);
servers.put(GrpcClientProtocolService.class.getName(), clientServer);
```

## 客户端和leader交互

### 0. proto文件

```protobuf
service RaftClientProtocolService {
  // A client-to-server stream RPC to ordered async requests
  rpc ordered(stream ratis.common.RaftClientRequestProto)
      returns (stream ratis.common.RaftClientReplyProto) {}

  // A client-to-server stream RPC for unordered async requests
  rpc unordered(stream ratis.common.RaftClientRequestProto)
      returns (stream ratis.common.RaftClientReplyProto) {}
}
```

可以看到两个方法都是双向流操作

### 1. 服务端

GrpcClientProtocolService

以ordered()方法为例，ordered()方法的处理逻辑存在于OrderedRequestStreamObserver对象中。OrderedRequestStreamObserver是RequestStreamObserver的子类，逻辑入口存在于RequestStreamObserver.onNext()方法中。**这里将使用protobuf序列化的参数RaftClientRequestProto类型转换为POJO类RaftClientRequest类型**

```java
@Override
public void onNext(RaftClientRequestProto request) {
  try {
    final RaftClientRequest r = ClientProtoUtils.toRaftClientRequest(request);
    processClientRequest(r);
  } catch (Exception e) {
    responseError(e, () -> "onNext for " + ClientProtoUtils.toString(request) + " in " + name);
  }
}
```

processClientRequest(RaftClientRequestProto)是抽象方法，交由子类实现，即OrderedRequestStreamObserver.processClientRequest(RaftClientRequestProto)方法

```java
@Override
void processClientRequest(RaftClientRequest r) {
  if (isClosed()) {
    final AlreadyClosedException exception = new AlreadyClosedException(getName() + ": the stream is closed");
    responseError(exception, () -> "processClientRequest (stream already closed) for " + r);
  }

  final RaftGroupId requestGroupId = r.getRaftGroupId();
  // use the group id in the first request as the group id of this observer
  final RaftGroupId updated = groupId.updateAndGet(g -> g != null ? g: requestGroupId);
  final PendingOrderedRequest pending = new PendingOrderedRequest(r);

  if (!requestGroupId.equals(updated)) {
    final GroupMismatchException exception = new GroupMismatchException(getId()
        + ": The group (" + requestGroupId + ") of " + r.getClientId()
        + " does not match the group (" + updated + ") of the " + JavaUtils.getClassSimpleName(getClass()));
    responseError(exception, () -> "processClientRequest (Group mismatched) for " + r);
    return;
  }

  slidingWindow.receivedRequest(pending, this::processClientRequest);
}
```

最终调用RequestStreamObserver.processClientRequest(RaftClientRequest, Consumer<RaftClientReply>)方法

```java
CompletableFuture<Void> processClientRequest(RaftClientRequest request, Consumer<RaftClientReply> replyHandler) {
  try {
    final String errMsg = LOG.isDebugEnabled() ? "processClientRequest for " + request : "";
    return protocol.submitClientRequestAsync(request
    ).thenAcceptAsync(replyHandler, executor
    ).exceptionally(exception -> {
      // TODO: the exception may be from either raft or state machine.
      // Currently we skip all the following responses when getting an
      // exception from the state machine.
      responseError(exception, () -> errMsg);
      return null;
    });
  } catch (IOException e) {
    throw new CompletionException("Failed processClientRequest for " + request + " in " + name, e);
  }
}
```

通过调用RaftServerProxy.submitClientRequestAsync(RaftClientRequest)方法最终调用RaftServerImpl.submitClientRequestAsync(RaftClientRequest)方法

```java
@Override
public CompletableFuture<RaftClientReply> submitClientRequestAsync(
    RaftClientRequest request) throws IOException {
  assertLifeCycleState(LifeCycle.States.RUNNING);
  LOG.debug("{}: receive client request({})", getMemberId(), request);
  final Optional<Timer> timer = Optional.ofNullable(raftServerMetrics.getClientRequestTimer(request.getType()));

  final CompletableFuture<RaftClientReply> replyFuture;

  if (request.is(TypeCase.STALEREAD)) {
    replyFuture = staleReadAsync(request);
  } else {
    // first check the server's leader state
    CompletableFuture<RaftClientReply> reply = checkLeaderState(request, null,
        !request.is(TypeCase.READ) && !request.is(TypeCase.WATCH));
    if (reply != null) {
      return reply;
    }

    // let the state machine handle read-only request from client
    RaftClientRequest.Type type = request.getType();
    if (type.is(TypeCase.MESSAGESTREAM)) {
      if (type.getMessageStream().getEndOfRequest()) {
        final CompletableFuture<RaftClientRequest> f = streamEndOfRequestAsync(request);
        if (f.isCompletedExceptionally()) {
          return f.thenApply(r -> null);
        }
        request = f.join();
        type = request.getType();
      }
    }

    if (type.is(TypeCase.READ)) {
      // TODO: We might not be the leader anymore by the time this completes.
      // See the RAFT paper section 8 (last part)
      replyFuture = processQueryFuture(stateMachine.query(request.getMessage()), request);
    } else if (type.is(TypeCase.WATCH)) {
      replyFuture = watchAsync(request);
    } else if (type.is(TypeCase.MESSAGESTREAM)) {
      replyFuture = streamAsync(request);
    } else {
      // query the retry cache
      final RetryCacheImpl.CacheQueryResult queryResult = retryCache.queryCache(ClientInvocationId.valueOf(request));
      final CacheEntry cacheEntry = queryResult.getEntry();
      if (queryResult.isRetry()) {
        // if the previous attempt is still pending or it succeeded, return its
        // future
        replyFuture = cacheEntry.getReplyFuture();
      } else {
        // TODO: this client request will not be added to pending requests until
        // later which means that any failure in between will leave partial state in
        // the state machine. We should call cancelTransaction() for failed requests
        TransactionContext context = stateMachine.startTransaction(filterDataStreamRaftClientRequest(request)); //1.在这里构造了TransactionContext对象，为了后续构造LogEntryProto对象
        if (context.getException() != null) {
          final StateMachineException e = new StateMachineException(getMemberId(), context.getException());
          final RaftClientReply exceptionReply = newExceptionReply(request, e);
          cacheEntry.failWithReply(exceptionReply);
          replyFuture = CompletableFuture.completedFuture(exceptionReply);
        } else {
            //这里，Handle a normal update request from client.
          replyFuture = appendTransaction(request, context, cacheEntry);
        }
      }
    }
  }

  final RaftClientRequest.Type type = request.getType();
  replyFuture.whenComplete((clientReply, exception) -> {
    if (clientReply.isSuccess()) {
      timer.map(Timer::time).ifPresent(Timer.Context::stop);
    }
    if (exception != null || clientReply.getException() != null) {
      raftServerMetrics.incFailedRequestCount(type);
    }
  });
  return replyFuture;
}
```

```java
private CompletableFuture<RaftClientReply> appendTransaction(
    RaftClientRequest request, TransactionContext context, CacheEntry cacheEntry) throws IOException {
  assertLifeCycleState(LifeCycle.States.RUNNING);
  CompletableFuture<RaftClientReply> reply;

  final PendingRequest pending;
  synchronized (this) {
    reply = checkLeaderState(request, cacheEntry, true);
    if (reply != null) {
      return reply;
    }

    // append the message to its local log
    final LeaderStateImpl leaderState = role.getLeaderStateNonNull();
    final PendingRequests.Permit permit = leaderState.tryAcquirePendingRequest(request.getMessage());
    if (permit == null) {
      cacheEntry.failWithException(new ResourceUnavailableException(
          getMemberId() + ": Failed to acquire a pending write request for " + request));
      return cacheEntry.getReplyFuture();
    }
    try {
      state.appendLog(context); //写入本地log，ServerState对象
    } catch (StateMachineException e) {
      // the StateMachineException is thrown by the SM in the preAppend stage.
      // Return the exception in a RaftClientReply.
      RaftClientReply exceptionReply = newExceptionReply(request, e);
      cacheEntry.failWithReply(exceptionReply);
      // leader will step down here
      if (e.leaderShouldStepDown() && getInfo().isLeader()) {
        leaderState.submitStepDownEvent(LeaderState.StepDownReason.STATE_MACHINE_EXCEPTION);
      }
      return CompletableFuture.completedFuture(exceptionReply);
    }

    // put the request into the pending queue
    pending = leaderState.addPendingRequest(permit, request, context); //写入pendingQueue
    if (pending == null) {
      cacheEntry.failWithException(new ResourceUnavailableException(
          getMemberId() + ": Failed to add a pending write request for " + request));
      return cacheEntry.getReplyFuture();
    }
    leaderState.notifySenders(); //通过appendEntries()将对应的logEntry发送给followers
  }
  return pending.getFuture();
}
```

跟进本地写logEntry的过程，即ServerState.appendLog(TransactionContext)方法

```java
void appendLog(TransactionContext operation) throws StateMachineException {
  getLog().append(currentTerm.get(), operation);
  Objects.requireNonNull(operation.getLogEntry());
}
```

其调用RaftLogBase.appendImpl(long, TrancsactionContext)方法

```java
private long appendImpl(long term, TransactionContext operation) throws StateMachineException {
  checkLogState();
  try(AutoCloseableLock writeLock = writeLock()) {
    final long nextIndex = getNextIndex();

    // This is called here to guarantee strict serialization of callback executions in case
    // the SM wants to attach a logic depending on ordered execution in the log commit order.
    try {
      operation = operation.preAppendTransaction();
    } catch (StateMachineException e) {
      throw e;
    } catch (IOException e) {
      throw new StateMachineException(memberId, e);
    }

    // build the log entry after calling the StateMachine
    final LogEntryProto e = operation.initLogEntry(term, nextIndex);

    int entrySize = e.getSerializedSize();
    if (entrySize > maxBufferSize) {
      throw new StateMachineException(memberId, new RaftLogIOException(
          "Log entry size " + entrySize + " exceeds the max buffer limit of " + maxBufferSize));
    }
    appendEntry(e);
    return nextIndex;
  }
}
```

这里的appendEntry(LogEntryProto)方法最终调用的是SegmentedRaftLog.appendEntryImpl(LogEntryProto)方法

```java
@Override
protected CompletableFuture<Long> appendEntryImpl(LogEntryProto entry) {
  final Timer.Context context = getRaftLogMetrics().getRaftLogAppendEntryTimer().time();
  checkLogState();
  if (LOG.isTraceEnabled()) {
    LOG.trace("{}: appendEntry {}", getName(), LogProtoUtils.toLogEntryString(entry));
  }
  try(AutoCloseableLock writeLock = writeLock()) {
    validateLogEntry(entry);
    final LogSegment currentOpenSegment = cache.getOpenSegment();
    if (currentOpenSegment == null) {
      cache.addOpenSegment(entry.getIndex());
      fileLogWorker.startLogSegment(entry.getIndex());
    } else if (isSegmentFull(currentOpenSegment, entry)) {
      cache.rollOpenSegment(true);
      fileLogWorker.rollLogSegment(currentOpenSegment);
    } else if (currentOpenSegment.numOfEntries() > 0 &&
        currentOpenSegment.getLastTermIndex().getTerm() != entry.getTerm()) {
      // the term changes
      final long currentTerm = currentOpenSegment.getLastTermIndex().getTerm();
      Preconditions.assertTrue(currentTerm < entry.getTerm(),
          "open segment's term %s is larger than the new entry's term %s",
          currentTerm, entry.getTerm());
      cache.rollOpenSegment(true);
      fileLogWorker.rollLogSegment(currentOpenSegment);
    }

    //TODO(runzhiwang): If there is performance problem, start a daemon thread to checkAndEvictCache
    checkAndEvictCache();

    // If the entry has state machine data, then the entry should be inserted
    // to statemachine first and then to the cache. Not following the order
    // will leave a spurious entry in the cache.
    CompletableFuture<Long> writeFuture =
        fileLogWorker.writeLogEntry(entry).getFuture();
    if (stateMachineCachingEnabled) {
      // The stateMachineData will be cached inside the StateMachine itself.
      cache.appendEntry(LogProtoUtils.removeStateMachineData(entry),
          LogSegment.Op.WRITE_CACHE_WITH_STATE_MACHINE_CACHE);
    } else {
      cache.appendEntry(entry, LogSegment.Op.WRITE_CACHE_WITHOUT_STATE_MACHINE_CACHE);
    }
    return writeFuture;
  } catch (Exception e) {
    LOG.error("{}: Failed to append {}", getName(), LogProtoUtils.toLogEntryString(entry), e);
    throw e;
  } finally {
    context.stop();
  }
}
```

### 2. 客户端

GrpcClientProtocolClient

## leader和Follower交互

### 0. proto文件

```protobuf
service RaftServerProtocolService {
  rpc requestVote(ratis.common.RequestVoteRequestProto)
      returns(ratis.common.RequestVoteReplyProto) {}

  rpc startLeaderElection(ratis.common.StartLeaderElectionRequestProto)
      returns(ratis.common.StartLeaderElectionReplyProto) {}

  rpc appendEntries(stream ratis.common.AppendEntriesRequestProto)
      returns(stream ratis.common.AppendEntriesReplyProto) {}

  rpc installSnapshot(stream ratis.common.InstallSnapshotRequestProto)
      returns(stream ratis.common.InstallSnapshotReplyProto) {}
}
```

### 1. 服务端

GrpcServerProtocolService

以appendEntries为例，这里返回ServerRequestStreamObserver对象，其处理逻辑在onNext()方法中

```java
public void onNext(REQUEST request) {
  if (!replyInOrder(request)) {
    try {
      process(request).thenAccept(this::handleReply);
    } catch (Exception e) {
      handleError(e, request);
    }
    return;
  }

  final PendingServerRequest<REQUEST> current = new PendingServerRequest<>(request);
  final PendingServerRequest<REQUEST> previous = previousOnNext.getAndSet(current);
  final CompletableFuture<Void> previousFuture = Optional.ofNullable(previous)
      .map(PendingServerRequest::getFuture)
      .orElse(CompletableFuture.completedFuture(null));
  try {
    process(request).exceptionally(e -> {
      // Handle cases, such as RaftServer is paused
      handleError(e, request);
      current.getFuture().completeExceptionally(e);
      return null;
    }).thenCombine(previousFuture, (reply, v) -> {
      handleReply(reply);
      current.getFuture().complete(null);
      return null;
    });
  } catch (Exception e) {
    handleError(e, request);
    current.getFuture().completeExceptionally(e);
  }
}
```

process(REQUEST)为抽象方法，具体实现在匿名内部类中

```java
@Override
CompletableFuture<AppendEntriesReplyProto> process(AppendEntriesRequestProto request) throws IOException {
  return server.appendEntriesAsync(request);
}
```

通过调用RaftServerProxy.appendEntries(AppendEntriesRequestProto)方法最终调用RaftServerImpl.appendEntries(AppendEntriesRequestProto)方法

```java
@Override
public CompletableFuture<AppendEntriesReplyProto> appendEntriesAsync(AppendEntriesRequestProto r)
    throws IOException {
  final RaftRpcRequestProto request = r.getServerRequest();
  final List<LogEntryProto> entries = r.getEntriesList();
  final TermIndex previous = r.hasPreviousLog()? TermIndex.valueOf(r.getPreviousLog()) : null;
  final RaftPeerId requestorId = RaftPeerId.valueOf(request.getRequestorId());

  preAppendEntriesAsync(requestorId, ProtoUtils.toRaftGroupId(request.getRaftGroupId()), r.getLeaderTerm(),
      previous, r.getLeaderCommit(), r.getInitializing(), entries);
  try {
    return appendEntriesAsync(requestorId, r.getLeaderTerm(), previous, r.getLeaderCommit(),
        request.getCallId(), r.getInitializing(), r.getCommitInfosList(), entries);
  } catch(Exception t) {
    LOG.error("{}: Failed appendEntriesAsync {}", getMemberId(), r, t);
    throw t;
  }
}
```



```java
private CompletableFuture<AppendEntriesReplyProto> appendEntriesAsync(
    RaftPeerId leaderId, long leaderTerm, TermIndex previous, long leaderCommit, long callId, boolean initializing,
    List<CommitInfoProto> commitInfos, List<LogEntryProto> entries) throws IOException {
  final boolean isHeartbeat = entries.isEmpty();
  logAppendEntries(isHeartbeat,
      () -> getMemberId() + ": receive appendEntries(" + leaderId + ", " + leaderTerm + ", "
          + previous + ", " + leaderCommit + ", " + initializing
          + ", commits:" + ProtoUtils.toString(commitInfos)
          + ", cId:" + callId
          + ", entries: " + LogProtoUtils.toLogEntriesString(entries));

  final long currentTerm;
  final long followerCommit = state.getLog().getLastCommittedIndex();
  final Optional<FollowerState> followerState;
  Timer.Context timer = raftServerMetrics.getFollowerAppendEntryTimer(isHeartbeat).time();
  synchronized (this) {
    // Check life cycle state again to avoid the PAUSING/PAUSED state.
    assertLifeCycleState(LifeCycle.States.STARTING_OR_RUNNING);
    final boolean recognized = state.recognizeLeader(leaderId, leaderTerm);
    currentTerm = state.getCurrentTerm();
    if (!recognized) {
      final AppendEntriesReplyProto reply = ServerProtoUtils.toAppendEntriesReplyProto(
          leaderId, getMemberId(), currentTerm, followerCommit, state.getNextIndex(), NOT_LEADER, callId,
          INVALID_LOG_INDEX, isHeartbeat);
      if (LOG.isDebugEnabled()) {
        LOG.debug("{}: Not recognize {} (term={}) as leader, state: {} reply: {}",
            getMemberId(), leaderId, leaderTerm, state, ServerStringUtils.toAppendEntriesReplyString(reply));
      }
      return CompletableFuture.completedFuture(reply);
    }
    try {
      changeToFollowerAndPersistMetadata(leaderTerm, true, "appendEntries");
    } catch (IOException e) {
      return JavaUtils.completeExceptionally(e);
    }
    state.setLeader(leaderId, "appendEntries");

    if (!initializing && lifeCycle.compareAndTransition(STARTING, RUNNING)) {
      role.startFollowerState(this, Op.APPEND_ENTRIES);
    }
    followerState = updateLastRpcTime(FollowerState.UpdateType.APPEND_START);

    // Check that the append entries are not inconsistent. There are 3
    // scenarios which can result in inconsistency:
    //      1. There is a snapshot installation in progress
    //      2. There is an overlap between the snapshot index and the entries
    //      3. There is a gap between the local log and the entries
    // In any of these scenarios, we should return an INCONSISTENCY reply
    // back to leader so that the leader can update this follower's next index.

    AppendEntriesReplyProto inconsistencyReply = checkInconsistentAppendEntries(
        leaderId, currentTerm, followerCommit, previous, callId, isHeartbeat, entries);
    if (inconsistencyReply != null) {
      followerState.ifPresent(fs -> fs.updateLastRpcTime(FollowerState.UpdateType.APPEND_COMPLETE));
      return CompletableFuture.completedFuture(inconsistencyReply);
    }

    state.updateConfiguration(entries);
  }

  final List<CompletableFuture<Long>> futures = entries.isEmpty() ? Collections.emptyList()
      : state.getLog().append(entries);
  commitInfos.forEach(commitInfoCache::update);

  CodeInjectionForTesting.execute(LOG_SYNC, getId(), null);
  if (!isHeartbeat) {
    final long installedIndex = snapshotInstallationHandler.getInstalledIndex();
    if (installedIndex >= RaftLog.LEAST_VALID_LOG_INDEX) {
      LOG.info("{}: Follower has completed install the snapshot {}.", this, installedIndex);
      stateMachine.event().notifySnapshotInstalled(InstallSnapshotResult.SUCCESS, installedIndex,
          getRaftServer().getPeer());
    }
  }
  return JavaUtils.allOf(futures).whenCompleteAsync(
      (r, t) -> followerState.ifPresent(fs -> fs.updateLastRpcTime(FollowerState.UpdateType.APPEND_COMPLETE)),
      serverExecutor
  ).thenApply(v -> {
    final AppendEntriesReplyProto reply;
    synchronized(this) {
      final long commitIndex = ServerImplUtils.effectiveCommitIndex(leaderCommit, previous, entries.size());
      state.updateCommitIndex(commitIndex, currentTerm, false);
      updateCommitInfoCache();
      final long n;
      final long matchIndex;
      if (!isHeartbeat) {
        LogEntryProto requestLastEntry = entries.get(entries.size() - 1);
        n = requestLastEntry.getIndex() + 1;
        matchIndex = requestLastEntry.getIndex();
      } else {
        n = state.getLog().getNextIndex();
        matchIndex = INVALID_LOG_INDEX;
      }
      reply = ServerProtoUtils.toAppendEntriesReplyProto(leaderId, getMemberId(), currentTerm,
          state.getLog().getLastCommittedIndex(), n, SUCCESS, callId, matchIndex,
          isHeartbeat);
    }
    logAppendEntries(isHeartbeat, () -> getMemberId() + ": succeeded to handle AppendEntries. Reply: "
        + ServerStringUtils.toAppendEntriesReplyString(reply));
    timer.stop();  // TODO: future never completes exceptionally?
    return reply;
  });
}
```

调用SegmentedRaftLog.appendImpl(List<LogEntryProto>)方法，进而调用SegmentedRaftLog.appendEntryImpl(LogEntryProto)方法



































